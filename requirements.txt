# Core LLM fine-tuning libraries
transformers>=4.35.0
torch>=2.0.0
peft>=0.6.0  # Parameter-Efficient Fine-Tuning (LoRA, QLoRA)
bitsandbytes>=0.41.0  # For quantization (QLoRA)
accelerate>=0.24.0
datasets>=2.14.0

# HuggingFace ecosystem
huggingface-hub>=0.17.0
tokenizers>=0.14.0
evaluate>=0.4.0

# Data processing
numpy
pandas
scikit-learn

# Utilities
requests
python-dotenv
tqdm

# Database (for Airflow)
psycopg2-binary

# Evaluation metrics
rouge-score
sacrebleu